{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac635dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/cosmosyw/Documents/Softwares/DNA_MERFISH_analysis/Startup.py\n",
    "\n",
    "import ImageAnalysis3 as ia\n",
    "\n",
    "from ImageAnalysis3 import *\n",
    "print(os.getpid())\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c3e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook = pd.read_csv(r'\\\\10.245.74.158\\Chromatin_NAS_8\\Exported_data\\20220713-Export\\merged_codebook.csv')\n",
    "\n",
    "postanalysis_folder = r'E:/DNA_analysis/Postanalysis_MeCP2/'\n",
    "if not os.path.exists(postanalysis_folder):\n",
    "    os.mkdir(postanalysis_folder)\n",
    "\n",
    "subclass_2_median_filename = os.path.join(postanalysis_folder, 'subclass_2_medianDict.pkl')\n",
    "print(subclass_2_median_filename)\n",
    "\n",
    "if os.path.exists(subclass_2_median_filename):\n",
    "    print(\"Loading\")\n",
    "    subclass_2_medianDict = np.load(subclass_2_median_filename, allow_pickle=True)\n",
    "    \n",
    "import ImageAnalysis3.structure_tools.distance as distance\n",
    "codebook_df = codebook.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaa8e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_subclasses = ['Oligo', 'L5 IT', 'Micro', 'Peri', 'Endo-PVM', 'Astro', 'OPC', 'L6 CT', 'L5 ET', 'L5/6 NP', 'Pvalb', 'L6 IT', 'Lamp5', 'L6b', 'Sst', 'L4/5 IT', 'L2/3 IT', 'Vip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b091dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_parent_folder = r'E:\\DNA_analysis\\Postanalysis_MeCP2\\AB_by_median\\subclass_MOp'\n",
    "if not os.path.exists(figure_parent_folder):\n",
    "    os.mkdir(figure_parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440b208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "_dpi = 300 # dpi required by figure\n",
    "_single_col_width = 2.25 # figure width in inch if occupy 1 colomn\n",
    "_double_col_width = 4.75 # figure width in inch if occupy 1 colomn\n",
    "_single_row_height= 2 # comparable height to match single-colomn-width\n",
    "_ticklabel_size=2\n",
    "_ticklabel_width=0.5\n",
    "_font_size=7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419920bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file IO\n",
    "figure_folder = os.path.join(figure_parent_folder, 'figure')\n",
    "if not os.path.exists(figure_folder):\n",
    "    os.mkdir(figure_folder)\n",
    "\n",
    "array_folder = os.path.join(figure_parent_folder, 'npy')\n",
    "if not os.path.exists(array_folder):\n",
    "    os.mkdir(array_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7affc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type_conversion = {'L4/5 IT':'L45 IT', 'L2/3 IT':'L23 IT', 'L5/6 NP':'L56 NP'}\n",
    "\n",
    "# load CG density\n",
    "\n",
    "# load CG density\n",
    "df_CG = pd.read_csv(r\"E:\\DNA_analysis\\refgen_with_loci_index_CG_Density.csv\")\n",
    "df_CG.sort_values('loci_index', inplace=True)\n",
    "df_CG.reset_index(inplace=True, drop=True)\n",
    "df_CG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8477a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_similarity_matrix(similarity_mat_input):\n",
    "    min_val = np.percentile(similarity_mat_input[np.where(similarity_mat_input!=0)],1)\n",
    "    max_val = np.percentile(similarity_mat_input[np.where(similarity_mat_input!=0)],99)\n",
    "    similarity_mat = (similarity_mat_input-min_val)/(max_val-min_val)\n",
    "    similarity_mat = np.clip(similarity_mat, 0 , 1)\n",
    "    return similarity_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3edc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "dict_subclass_pc_values = {}\n",
    "dict_subclass_pc_values['loci_name'] = df_subclass_ab['loci_name'].values\n",
    "\n",
    "for sel_type in sel_subclasses:\n",
    "    \n",
    "    fig = plt.figure(figsize=(4,6), dpi=300)\n",
    "    \n",
    "    if sel_type in cell_type_conversion.keys():\n",
    "        output_type = cell_type_conversion[sel_type]\n",
    "    else:\n",
    "        output_type = sel_type\n",
    "    \n",
    "    wt_npy_file = os.path.join(array_folder, f'{output_type}_WT_similarity_matrix.npy')\n",
    "    ko_npy_file = os.path.join(array_folder, f'{output_type}_KO_similarity_matrix.npy')\n",
    "    if os.path.exists(wt_npy_file):\n",
    "        wt_similarity_mat = np.load(wt_npy_file)\n",
    "    else:\n",
    "        summary_dict = subclass_2_medianDict[sel_type+'_WT']\n",
    "        sel_codebook = codebook_df\n",
    "        sort_by_region = False\n",
    "        # calculate similarity matrix\n",
    "        _trans_mat_wt, chr_edges, chr_names = distance.assemble_ChrDistDict_2_Matrix(\n",
    "            summary_dict, codebook_df, \n",
    "            sel_codebook=sel_codebook, \n",
    "            use_cis=False, use_trans=True, sort_by_region=sort_by_region,\n",
    "        )\n",
    "        _trans_mat_wt = _trans_mat_wt[:1981, :1981].copy()\n",
    "        norm_trans_wt = _trans_mat_wt.copy()\n",
    "        for i in range(chr_edges.shape[0]-2):\n",
    "            col_start = chr_edges[i]\n",
    "            col_end = chr_edges[i+1]\n",
    "\n",
    "            for j in range(chr_edges.shape[0]-2):\n",
    "                row_start = chr_edges[j]\n",
    "                row_end = chr_edges[j+1]\n",
    "\n",
    "                temp_mat = _trans_mat_wt[row_start:row_end, col_start:col_end]\n",
    "                temp_norm = np.nanmean(temp_mat, axis=1)\n",
    "\n",
    "                norm_trans_wt[row_start:row_end, col_start:col_end] = temp_mat/temp_norm.reshape((temp_norm.shape[0],1))\n",
    "        # generate similarity matrix\n",
    "        wt_similarity_mat = norm_trans_wt.copy()\n",
    "\n",
    "        for i in range(wt_similarity_mat.shape[0]):\n",
    "            for j in range(wt_similarity_mat.shape[1]):\n",
    "                x = norm_trans_wt[:,i].copy()\n",
    "                y = norm_trans_wt[:,j].copy()\n",
    "                mask = (~np.isnan(x))&(~np.isinf(x))&(~np.isnan(y))&(~np.isinf(y))\n",
    "                x = x[mask]\n",
    "                y = y[mask]\n",
    "                wt_similarity_mat[i,j] = euclidean(x, y)\n",
    "        # save\n",
    "        np.save(wt_npy_file, wt_similarity_mat)\n",
    "    ### KO files\n",
    "    if os.path.exists(ko_npy_file):\n",
    "        ko_similarity_mat = np.load(ko_npy_file)\n",
    "    else:\n",
    "        summary_dict = subclass_2_medianDict[sel_type+'_KO']\n",
    "        sel_codebook = codebook_df\n",
    "        sort_by_region = False\n",
    "        # calculate similarity matrix\n",
    "        _trans_mat_wt, chr_edges, chr_names = distance.assemble_ChrDistDict_2_Matrix(\n",
    "            summary_dict, codebook_df, \n",
    "            sel_codebook=sel_codebook, \n",
    "            use_cis=False, use_trans=True, sort_by_region=sort_by_region,\n",
    "        )\n",
    "        _trans_mat_wt = _trans_mat_wt[:1981, :1981].copy()\n",
    "        norm_trans_wt = _trans_mat_wt.copy()\n",
    "        for i in range(chr_edges.shape[0]-2):\n",
    "            col_start = chr_edges[i]\n",
    "            col_end = chr_edges[i+1]\n",
    "\n",
    "            for j in range(chr_edges.shape[0]-2):\n",
    "                row_start = chr_edges[j]\n",
    "                row_end = chr_edges[j+1]\n",
    "\n",
    "                temp_mat = _trans_mat_wt[row_start:row_end, col_start:col_end]\n",
    "                temp_norm = np.nanmean(temp_mat, axis=1)\n",
    "\n",
    "                norm_trans_wt[row_start:row_end, col_start:col_end] = temp_mat/temp_norm.reshape((temp_norm.shape[0],1))\n",
    "        # generate similarity matrix\n",
    "        ko_similarity_mat = norm_trans_wt.copy()\n",
    "\n",
    "        for i in range(ko_similarity_mat.shape[0]):\n",
    "            for j in range(ko_similarity_mat.shape[1]):\n",
    "                x = norm_trans_wt[:,i].copy()\n",
    "                y = norm_trans_wt[:,j].copy()\n",
    "                mask = (~np.isnan(x))&(~np.isinf(x))&(~np.isnan(y))&(~np.isinf(y))\n",
    "                x = x[mask]\n",
    "                y = y[mask]\n",
    "                ko_similarity_mat[i,j] = euclidean(x, y)\n",
    "        # save\n",
    "        np.save(ko_npy_file, ko_similarity_mat)\n",
    "    \n",
    "    # get rid off X chromosomes and define all parameters\n",
    "    wt_similarity_mat = wt_similarity_mat[:1917, :1917].copy()\n",
    "    ko_similarity_mat = ko_similarity_mat[:1917, :1917].copy()\n",
    "    \n",
    "    # concatenate and normalize\n",
    "    wt_similarity_mat = normalize_similarity_matrix(wt_similarity_mat)\n",
    "    ko_similarity_mat = normalize_similarity_matrix(ko_similarity_mat)\n",
    "    similarity_mat = np.concatenate((wt_similarity_mat, ko_similarity_mat), axis=1)\n",
    "    \n",
    "    \n",
    "    # PCA on similarity matrices - WT\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(wt_similarity_mat)\n",
    "    pc1 = pca.components_[0]\n",
    "    norm_pc1_wt = pc1/np.nanstd(pc1)\n",
    "    pc2 = pca.components_[1]\n",
    "    norm_pc2_wt = pc2/np.nanstd(pc2)\n",
    "    \n",
    "    # figure out the sign\n",
    "    CG_density = df_CG.CG_density_1Mb.values\n",
    "    r, p = pearsonr(norm_pc1_wt, CG_density)\n",
    "    if r<0:\n",
    "        norm_pc1_wt = -norm_pc1_wt\n",
    "        \n",
    "    # PCA on similarity matrices - KO\n",
    "    pca = PCA(n_components=3)\n",
    "    pca.fit(ko_similarity_mat)\n",
    "    pc1 = pca.components_[0]\n",
    "    norm_pc1_ko = pc1/np.nanstd(pc1)\n",
    "    pc2 = pca.components_[1]\n",
    "    norm_pc2_ko = pc2/np.nanstd(pc2)\n",
    "    \n",
    "    # figure out the sign\n",
    "    CG_density = df_CG.CG_density_1Mb.values\n",
    "    r, p = pearsonr(norm_pc1_ko, CG_density)\n",
    "    if r<0:\n",
    "        norm_pc1_ko = -norm_pc1_ko\n",
    "        \n",
    "    norm_pc1 = np.concatenate((norm_pc1_wt, norm_pc1_ko), axis=0)\n",
    "    norm_pc2 = np.concatenate((norm_pc2_wt, norm_pc2_ko), axis=0)\n",
    "    \n",
    "    dict_subclass_pc_values[sel_type+'_WT'] = norm_pc1[:1917]\n",
    "    dict_subclass_pc_values[sel_type+'_KO'] = norm_pc1[1917:]\n",
    "    \n",
    "    # plot\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    # create a color map\n",
    "    current_cmap = cm.get_cmap('seismic_r').copy()\n",
    "    current_cmap.set_bad(color=[0.5,0.5,0.5,1])\n",
    "    \n",
    "    # common parameters\n",
    "    chr_edges = np.array([   0,  153,  301,  424,  546,  665,  779,  875,  977, 1079, 1196,\n",
    "           1302, 1380, 1472, 1566, 1644, 1720, 1790, 1858, 1917])\n",
    "    chr_names = []\n",
    "    for i in range(1,20):\n",
    "        chr_names.append('chr'+str(i))\n",
    "    #plot\n",
    "    _pf = ax1.imshow(similarity_mat, \n",
    "                     cmap=current_cmap, vmin=0, vmax=0.4)\n",
    "    ax1.set_title(sel_type, fontsize=7)\n",
    "    ax1.set_yticks((chr_edges[1:] + chr_edges[:-1])/2, chr_names, fontsize=6)\n",
    "    ax1.plot([1917, 1917], [0, 1916], color='black', linewidth=0.75)\n",
    "    # locate ax1\n",
    "    divider = make_axes_locatable(ax1)\n",
    "   \n",
    "    # colorbar ax\n",
    "    cax = divider.append_axes('right', size='2%', pad=\"2%\")\n",
    "    cbar = plt.colorbar(_pf,cax=cax, ax=ax1, ticks=[0,0.2,0.4])\n",
    "    cbar.ax.set_yticklabels([0,0.2,0.4])\n",
    "    cbar.ax.tick_params('both', labelsize=_font_size-1, \n",
    "                    width=_ticklabel_width, length=_ticklabel_size-0.5,\n",
    "                    pad=1, labelleft=False) # remove bottom ticklabels for ax1\n",
    "    [i[1].set_linewidth(_ticklabel_width) for i in cbar.ax.spines.items()]\n",
    "    #cbar.set_ticks([vmin,vmax])\n",
    "    cbar.outline.set_linewidth(_ticklabel_width)\n",
    "    cbar.set_label('Similarity for trans distance', \n",
    "                   fontsize=_font_size, labelpad=2, rotation=270)\n",
    "    cbar.ax.minorticks_off()\n",
    "    # create bottom ax\n",
    "    bot_ax = divider.append_axes('bottom', size='10%', pad=\"2%\", \n",
    "                                 sharex=ax1, xticks=[])\n",
    "    bot_ax.bar(np.where(norm_pc1>0)[0], norm_pc1[norm_pc1>0], color='r', width=1, bottom=0)\n",
    "    bot_ax.bar(np.where(norm_pc1<=0)[0], norm_pc1[norm_pc1<=0],color='b', width=1, bottom=0)\n",
    "\n",
    "    bot_ax.tick_params('x', labelsize=_font_size-1, \n",
    "                    width=_ticklabel_width, length=_ticklabel_size,\n",
    "                    pad=1, labelleft=False, labelbottom=True) # remove bottom ticklabels for ax1\n",
    "    bot_ax.tick_params('y', labelsize=_font_size-1, \n",
    "                    width=_ticklabel_width, length=0,\n",
    "                    pad=1, labelleft=False, labelbottom=True) # remove bottom ticklabels for ax1\n",
    "    bot_ax.set_ylabel('PC1', fontsize=_font_size-1, labelpad=1, loc='top', rotation='horizontal')\n",
    "    bot_ax.yaxis.set_label_coords(-0.01, .2)\n",
    "    bot_ax.plot([1917, 1917], [-2, 2], color='black', linewidth=0.75)\n",
    "    \n",
    "    # create bottom ax\n",
    "    bot_ax = divider.append_axes('bottom', size='10%', pad=\"2%\", \n",
    "                                 sharex=ax1, xticks=[])\n",
    "    bot_ax.bar(np.where(norm_pc2>0)[0], norm_pc2[norm_pc2>0], color='r', width=1, bottom=0)\n",
    "    bot_ax.bar(np.where(norm_pc2<=0)[0], norm_pc2[norm_pc2<=0],color='b', width=1, bottom=0)\n",
    "\n",
    "    bot_ax.tick_params('x', labelsize=_font_size-1, \n",
    "                    width=_ticklabel_width, length=_ticklabel_size,\n",
    "                    pad=1, labelleft=False, labelbottom=True) # remove bottom ticklabels for ax1\n",
    "    bot_ax.tick_params('y', labelsize=_font_size-1, \n",
    "                    width=_ticklabel_width, length=0,\n",
    "                    pad=1, labelleft=False, labelbottom=True) # remove bottom ticklabels for ax1\n",
    "    bot_ax.set_ylabel('PC2', fontsize=_font_size-1, labelpad=1, loc='top', rotation='horizontal')\n",
    "    bot_ax.yaxis.set_label_coords(-0.01, .2)\n",
    "    bot_ax.plot([1917, 1917], [-2, 10], color='black', linewidth=0.75)\n",
    "    \n",
    "    plt.savefig(os.path.join(figure_folder,  f'{output_type}_AB.pdf'))\n",
    "    plt.savefig(os.path.join(figure_folder,  f'{output_type}_AB.png'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff1a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subclass_Mecp2_PC = pd.DataFrame(dict_subclass_pc_values)\n",
    "df_subclass_Mecp2_PC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde2b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subclass_Mecp2_PC.to_csv(r'result\\Mecp2_subclass_PC_values_call_Separate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502e70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merlin_postanalysis",
   "language": "python",
   "name": "merlin_postanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
